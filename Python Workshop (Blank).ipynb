{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3CWRGRFjzadp"
   },
   "source": [
    "# Python Workshop\n",
    "\n",
    "Importing different libraries allows us to access and use the functions stored inside them. These six lines are the most commonly used data science packages and settings, so it's good practice to include at the top of every notebook you open."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-18T20:26:40.510531Z",
     "start_time": "2018-09-18T20:26:28.867692Z"
    },
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Ckirx_M7zqmi"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c43cKMTBzyfj"
   },
   "source": [
    "## Section 1: Variables, types, and basic math operations\n",
    "---\n",
    "So far, we've added the following *operations* to our toolbox:\n",
    "- `+` , `-` , `*` , `/` : Add, subtract, multiply, divide\n",
    "- `=` : Assign variables\n",
    "- `<`, `>`, `<=`, `>=`, `==`: Compare values\n",
    "---\n",
    "\n",
    "Suppose we have the following data on Covid-19 cases:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZYfk-b9N2fni"
   },
   "source": [
    "<header><h4 align='center'>Covid-19 Cases</h4></header>\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <td><b>Date</b></td>\n",
    "            <td><b>Country</b></td>\n",
    "            <td><b>Cumulative Cases</b></td>\n",
    "            <td><b>Cumulative Deaths</b></td>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tr>\n",
    "        <td>3/14</td>\n",
    "        <td>USA</td>\n",
    "        <td>2943</td>\n",
    "        <td>57</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>3/14</td>\n",
    "        <td>Italy</td>\n",
    "        <td>21157</td>\n",
    "        <td>1441</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>3/15</td>\n",
    "        <td>USA</td>\n",
    "        <td>3754</td>\n",
    "        <td>68</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>3/15</td>\n",
    "        <td>Italy</td>\n",
    "        <td>24747</td>\n",
    "        <td>1809</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "imwZ3SLr6T3m"
   },
   "source": [
    "**Task:** \n",
    "- Assign four variables to represent cumulative cases for the United States and Italy for 3/14 and 3/15.\n",
    "- Use these four variables to create two new variables that represent the number of new cases on 3/15 for each country.\n",
    "- Use the two profit variables to calculate the total number of new cases in Italy and the US."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-18T20:26:40.520027Z",
     "start_time": "2018-09-18T20:26:40.514171Z"
    },
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 266,
     "status": "ok",
     "timestamp": 1523924871734,
     "user": {
      "displayName": "Jun Seo Park",
      "photoUrl": "//lh6.googleusercontent.com/-KIeDOii6NOY/AAAAAAAAAAI/AAAAAAAAAA4/BO9dUEBtd8E/s50-c-k-no/photo.jpg",
      "userId": "116991900080281348598"
     },
     "user_tz": 420
    },
    "id": "-nh2Wffz0944",
    "outputId": "f1abd589-bb2e-420a-e868-02bfb42be1af"
   },
   "outputs": [],
   "source": [
    "# Number of cumulative COVID-19 cases in Italy and USA on 3/14 and 3/15\n",
    "\n",
    "italy_314 = ...\n",
    "usa_314 = ...\n",
    "italy_315 = ...\n",
    "usa_315 = ...\n",
    "\n",
    "print(italy_314, usa_314, italy_315, usa_315)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-18T20:26:40.527323Z",
     "start_time": "2018-09-18T20:26:40.523717Z"
    },
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 420,
     "status": "ok",
     "timestamp": 1523924882960,
     "user": {
      "displayName": "Jun Seo Park",
      "photoUrl": "//lh6.googleusercontent.com/-KIeDOii6NOY/AAAAAAAAAAI/AAAAAAAAAA4/BO9dUEBtd8E/s50-c-k-no/photo.jpg",
      "userId": "116991900080281348598"
     },
     "user_tz": 420
    },
    "id": "y1mV5ZJ6C1fb",
    "outputId": "6527d7bd-b701-4eeb-a7cc-2671af8ecbed"
   },
   "outputs": [],
   "source": [
    "# New cases\n",
    "\n",
    "new_cases_italy = ...\n",
    "new_cases_usa = ...\n",
    "\n",
    "print(new_cases_italy, new_cases_usa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-18T20:26:40.536651Z",
     "start_time": "2018-09-18T20:26:40.529775Z"
    },
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 526,
     "status": "ok",
     "timestamp": 1523924889934,
     "user": {
      "displayName": "Jun Seo Park",
      "photoUrl": "//lh6.googleusercontent.com/-KIeDOii6NOY/AAAAAAAAAAI/AAAAAAAAAA4/BO9dUEBtd8E/s50-c-k-no/photo.jpg",
      "userId": "116991900080281348598"
     },
     "user_tz": 420
    },
    "id": "q_8qmmxn7pLR",
    "outputId": "f88d78e7-6e23-4412-9bf5-316e0440336b"
   },
   "outputs": [],
   "source": [
    "# Combined new cases\n",
    "\n",
    "total_new_cases = ...\n",
    "\n",
    "total_new_cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0tEvAd-J7yUN"
   },
   "source": [
    "**Task:**\n",
    "  - What was the average number of new cases per hour in Italy and the US\n",
    "  - Doctors are working hard to limit number of new cases per hour to 180. Did they achieve this? Format the answer as a boolean (`True` or `False`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-18T20:26:40.543112Z",
     "start_time": "2018-09-18T20:26:40.539100Z"
    },
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 294,
     "status": "ok",
     "timestamp": 1523924637026,
     "user": {
      "displayName": "Jun Seo Park",
      "photoUrl": "//lh6.googleusercontent.com/-KIeDOii6NOY/AAAAAAAAAAI/AAAAAAAAAA4/BO9dUEBtd8E/s50-c-k-no/photo.jpg",
      "userId": "116991900080281348598"
     },
     "user_tz": 420
    },
    "id": "zX_7nJ8Hz-Cd",
    "outputId": "cee45243-aabf-4e2e-be54-e363032e2705"
   },
   "outputs": [],
   "source": [
    "# Monthly profit figures\n",
    "\n",
    "average_new_cases_per_hour = ...\n",
    "\n",
    "average_new_cases_per_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-18T20:26:40.550714Z",
     "start_time": "2018-09-18T20:26:40.545826Z"
    },
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 384,
     "status": "ok",
     "timestamp": 1523924637530,
     "user": {
      "displayName": "Jun Seo Park",
      "photoUrl": "//lh6.googleusercontent.com/-KIeDOii6NOY/AAAAAAAAAAI/AAAAAAAAAA4/BO9dUEBtd8E/s50-c-k-no/photo.jpg",
      "userId": "116991900080281348598"
     },
     "user_tz": 420
    },
    "id": "rHcp7bxJ2Bvc",
    "outputId": "62ca8e04-5334-488f-a341-863274e73400"
   },
   "outputs": [],
   "source": [
    "# Success?\n",
    "\n",
    "success = ...\n",
    "\n",
    "success"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EQAPXRQsAEQV"
   },
   "source": [
    "## Section 2: Lists, loops, and conditionals\n",
    "---\n",
    "We now have additional tools in our toolbox:\n",
    "- Lists allow us to store multiple values in one variable\n",
    "- Loops allow us to operate on lists by *iterating* through each value in the list\n",
    "- Conditionals allow us to perform operations only if a condition is met\n",
    "---\n",
    "Let's look into the number of Covid-19 cases/deaths in Italy a little deeper\n",
    "\n",
    "| Date    |   Cumulative Cases |   Cumulative Deaths |\n",
    "|:--------|------------:|---------:|\n",
    "| 3/1/20  |        1694 |       34 |\n",
    "| 3/2/20  |        2036 |       52 |\n",
    "| 3/3/20  |        2502 |       79 |\n",
    "| 3/4/20  |        3089 |      107 |\n",
    "| 3/5/20  |        3858 |      148 |\n",
    "| 3/6/20  |        4636 |      197 |\n",
    "| 3/7/20  |        5883 |      233 |\n",
    "| 3/8/20  |        7375 |      366 |\n",
    "| 3/9/20  |        9172 |      463 |\n",
    "| 3/10/20 |       10149 |      631 |\n",
    "| 3/11/20 |       12462 |      827 |\n",
    "| 3/12/20 |       15133 |     1016 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ULjh_XjFN9bQ"
   },
   "source": [
    "Then, the \"Cumulative Cases\" and \"Cumulative Deaths\" columns can be represented using two lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-18T20:26:40.557285Z",
     "start_time": "2018-09-18T20:26:40.554021Z"
    },
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "WOg-PPb4H6eZ"
   },
   "outputs": [],
   "source": [
    "cumulative_cases = [1694, 2036, 2502, 3089, 3858, 4636, 5883, 7375, 9172, 10149, 12462, 15133]\n",
    "cumulative_deaths = [34, 52, 79, 107, 148, 197, 233, 366, 463, 631, 827, 1016]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new list with the number of new cases per day\n",
    "\n",
    "new_cases = np.diff(cumulative_cases)\n",
    "new_cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gZQQPu3UOVj6"
   },
   "source": [
    "**Task:**\n",
    "- Find the average number of new cases per day, using `new_cases`\n",
    "- Using a loop, print out the average number of new cases per hour for each day\n",
    "- Only print out the average number of new cases per hour if it's larger than <strong>50</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-18T20:26:40.564325Z",
     "start_time": "2018-09-18T20:26:40.559622Z"
    },
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 347,
     "status": "ok",
     "timestamp": 1523925323264,
     "user": {
      "displayName": "Jun Seo Park",
      "photoUrl": "//lh6.googleusercontent.com/-KIeDOii6NOY/AAAAAAAAAAI/AAAAAAAAAA4/BO9dUEBtd8E/s50-c-k-no/photo.jpg",
      "userId": "116991900080281348598"
     },
     "user_tz": 420
    },
    "id": "0JnRybSXRWjD",
    "outputId": "75cf3cc3-8a0d-40e1-aba0-0380fc441d3d"
   },
   "outputs": [],
   "source": [
    "# Mean\n",
    "\n",
    "average_new_cases = ...\n",
    "\n",
    "print(average_new_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average number of new cases per hour per day\n",
    "\n",
    "for i in ...:\n",
    "    print(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average number of new cases per hour per day only if its larger than 50\n",
    "\n",
    "for i in ...:\n",
    "    per_hour = ...\n",
    "    if ...:\n",
    "        print(per_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ns7PAYGmXa3q"
   },
   "source": [
    "**Task:** \n",
    "- (Challenging!) Let's calculate the number of new deaths per day using `cumulative_deaths`.\n",
    "- We did this with `np.diff` before, but let's implement what the function is doing!\n",
    "- Use a loop to calculate the day-by-day change in number of deaths.\n",
    "  - Hint: Since we have data for 12 days (`len(cumulative_deaths)`), there are 11 values that we will want to calculate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-18T20:26:40.615638Z",
     "start_time": "2018-09-18T20:26:40.607544Z"
    },
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 315,
     "status": "ok",
     "timestamp": 1523865207981,
     "user": {
      "displayName": "Jun Seo Park",
      "photoUrl": "//lh6.googleusercontent.com/-KIeDOii6NOY/AAAAAAAAAAI/AAAAAAAAAA4/BO9dUEBtd8E/s50-c-k-no/photo.jpg",
      "userId": "116991900080281348598"
     },
     "user_tz": 420
    },
    "id": "7kJNxx49X5vv",
    "outputId": "7a44cefd-ec7f-4a88-f1ed-e141482218ea"
   },
   "outputs": [],
   "source": [
    "# Number of new deaths per day\n",
    "\n",
    "new_deaths = []\n",
    "\n",
    "for i in ...: \n",
    "    ...\n",
    "    new_deaths.append(...)\n",
    "    \n",
    "new_deaths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Numpy\n",
    "---\n",
    "New tools:\n",
    "- Numpy arrays: a list-like data structure much better suited for mathmatical operations\n",
    "- Numpy functions: mathmatical functions that can be applied on numpy arrays and lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task:**\n",
    "- For the average number of new deaths per day (`new_deaths`), find the following using Numpy functions:\n",
    "  - Mean ([`np.mean`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.mean.html))\n",
    "  - Standard deviation ([`np.std`](https://docs.scipy.org/doc/numpy-dev/reference/generated/numpy.std.html))\n",
    "  - 25, 50, 75th percentiles ([`np.percentile`](https://docs.scipy.org/doc/numpy-dev/reference/generated/numpy.percentile.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean\n",
    "\n",
    "average_new_deaths = ...\n",
    "\n",
    "print(average_new_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard deviation\n",
    "\n",
    "new_deaths_std = ...\n",
    "\n",
    "print(new_deaths_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 25, 50, 75th percentiles\n",
    "\n",
    "new_deaths_perc = ...\n",
    "\n",
    "print(new_deaths_perc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we complete the next task, observe the following two cells to observe the difference between the two:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[1, 2, 3] + [4, 5, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([1, 2, 3]) + np.array([1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that for lists, the `+` operator *concatenates* them, while for numpy arrays, `+`  performs *element-wise* addition. \n",
    "\n",
    "**Task:**\n",
    "- Using `cumulative_cases` and `cumulative_deaths`, find the death rate per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# death rate per day\n",
    "\n",
    "death_rate = ...\n",
    "\n",
    "print(death_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jH6am5vjCZbU"
   },
   "source": [
    "## Section 4: Using Pandas to Manipulate Data\n",
    "---\n",
    "New tools (assume `df` is a DataFrame, `colname` is the name of a column):\n",
    "- [`pd.read_csv`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) to read CSV files\n",
    "- `df.head()` to view the first 5 lines\n",
    "- `df['colname']` to view a column as a `Series`\n",
    "- `df[['colname1', 'colname2']]` to view multiple columns as a `DataFrame` \n",
    "- `df.loc[_____, _____]` to view certain rows and columns based on index names\n",
    "- `df.iloc[_____, _____]` to view certain rows and columns based on numerical indices\n",
    "---\n",
    "\n",
    "Switching gears, we'll move to a real-life dataset of Kiva loans.\n",
    "\n",
    "**Task:**\n",
    "- Read in the Kiva dataset; let's call it `loans`.\n",
    "- View the first five lines to get a grasp of what the data looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if data file is unzipped, if not unzip it\n",
    "\n",
    "import os  \n",
    "path = 'data/kiva_loans.csv'\n",
    "if not os.path.isfile(path):\n",
    "    !unzip data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-18T20:26:48.054043Z",
     "start_time": "2018-09-18T20:26:40.627097Z"
    },
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "tHByP7ObFVyL"
   },
   "outputs": [],
   "source": [
    "# Read in dataset\n",
    "loans = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-18T20:26:48.119954Z",
     "start_time": "2018-09-18T20:26:48.058779Z"
    }
   },
   "outputs": [],
   "source": [
    "# View first five lines\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task:**\n",
    "\n",
    "It's always good practice to do two things once we first load a dataset:\n",
    "- Use `.shape` to find the dimensions of the data\n",
    "- Use `.isnull().sum()` to find how many values are missing from each column\n",
    "    - (Optional) If you'd like to know how/why this works, check out the documentation for [`df.isnull()`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.isnull.html) and [`df.sum()`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sum.html), and try each separately on `loans`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-18T20:26:48.127454Z",
     "start_time": "2018-09-18T20:26:48.123539Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dimensions of data\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-18T20:26:49.122915Z",
     "start_time": "2018-09-18T20:26:48.130393Z"
    }
   },
   "outputs": [],
   "source": [
    "# Number of missing values from each column\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task:**\n",
    "\n",
    "For these next two tasks, use only square brackets (not `.loc` or `.iloc`).\n",
    "- Take a look at the `use` column by itself, as a `Series`\n",
    "- Take a look at the `sector` and `use` columns together, as a `DataFrame`\n",
    "    - Do you notice anything odd about the `sector` column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-18T20:26:49.132957Z",
     "start_time": "2018-09-18T20:26:49.126068Z"
    }
   },
   "outputs": [],
   "source": [
    "# 'use' column\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-18T20:26:49.173921Z",
     "start_time": "2018-09-18T20:26:49.135178Z"
    }
   },
   "outputs": [],
   "source": [
    "# 'sector' and 'use' columns\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-17T01:12:59.992705Z",
     "start_time": "2018-04-17T01:12:59.362425Z"
    }
   },
   "source": [
    "**Task:**\n",
    "\n",
    "For these next three tasks, use only square brackets (not `.loc` or `.iloc`).\n",
    "- View the rows that have a `sector` value of `Tranpotation`. \n",
    "    - What format is this?\n",
    "- Replace the `Tranpotation` values with `Transportation`.\n",
    "    - Are you seeing a warning? Why might this happen?\n",
    "- Check `loans.head()`. Did we correctly replace the `Tranpotation` values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-18T20:26:49.428922Z",
     "start_time": "2018-09-18T20:26:49.178095Z"
    }
   },
   "outputs": [],
   "source": [
    "# View rows with the sector Tranpotation\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-18T20:26:49.619627Z",
     "start_time": "2018-09-18T20:26:49.434079Z"
    }
   },
   "outputs": [],
   "source": [
    "# Attempt to replace Tranpotation with Transportation using square brackets\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Better - use the Series.replace() method \n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-18T20:26:49.661334Z",
     "start_time": "2018-09-18T20:26:49.623845Z"
    }
   },
   "outputs": [],
   "source": [
    "# Verify correct(?) replacement\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task:**\n",
    "- Using `.loc[_____, ______]`, replace the `Tranpotation` values with `Transportation`.\n",
    "- Verify using `loans.head()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-18T20:26:49.786202Z",
     "start_time": "2018-09-18T20:26:49.664153Z"
    }
   },
   "outputs": [],
   "source": [
    "# Replace Tranpotation with Transportation using .loc\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-18T20:26:49.833121Z",
     "start_time": "2018-09-18T20:26:49.789620Z"
    }
   },
   "outputs": [],
   "source": [
    "# Verify correct replacement\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Working with Aggregate Data\n",
    "---\n",
    "More tools in our toolbox! Again, assume `df` is a DataFrame and `colname` is the name of a column.\n",
    "- [`df.groupby(colname)`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html): Places each row of a DataFrame into a group based on certain column values\n",
    "- `df.groupby(colname).function()` applies `function()` to each group. Possible functions include:\n",
    "    - `count()`: number of non-NA rows in each group\n",
    "    - `mean()`: mean of all values in each group\n",
    "    - `std()`: standard deviation of all values in each group\n",
    "    - `min()`: minimum of all values in each group\n",
    "    - `max()`: maximum of all values in each group\n",
    "    - `median()`: median of all values in each group\n",
    "---\n",
    "\n",
    "**Task:**\n",
    "- Find the number of loans for each sector\n",
    "- Find the average loan amount for each country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-18T20:26:50.827803Z",
     "start_time": "2018-09-18T20:26:49.836753Z"
    }
   },
   "outputs": [],
   "source": [
    "# Number of loans for each sector\n",
    "loans_by_sector = ...\n",
    "\n",
    "loans_by_sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-18T20:26:51.223180Z",
     "start_time": "2018-09-18T20:26:50.832493Z"
    }
   },
   "outputs": [],
   "source": [
    "# Average loan amount for each country\n",
    "average_loan_by_country = ...\n",
    "\n",
    "average_loan_by_country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: Graphing\n",
    "---\n",
    "Basic graphing tools:\n",
    "- [`plt.plot(x, y)`](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.plot.html): Line graph\n",
    "- [`plt.scatter(x, y)`](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.scatter.html): Scatter plot\n",
    "- [`plt.bar(x, height)`](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.bar.html): Bar chart\n",
    "- [`plt.hist(x)`](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.hist.html): Histogram\n",
    "- [`plt.figure(figsize=(__, __))`](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.figure.html): Set figure size\n",
    "- [`plt.xlabel(_____)`](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.xlabel.html), [`plt.ylabel(_____)`](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.xlabel.html): Set x-axis and y-axis labels\n",
    "- [`plt.xlim(_____)`](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.xlim.html), [`plt.ylim(_____)`](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.ylim.html): Set x-axis and y-axis limits\n",
    "- [`plt.title(_____)`](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.title.html): Set title\n",
    "- [`plt.legend()`](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.legend.html): Show legend (assuming you have assigned labels; e.g. `plt.scatter(x, y, label='United States')`)\n",
    "- Note that you can control almost any small detail on the graph! Color, line width/scatterpoint size, rotating axis tick-mark labels, etc. Chances are, someone else has had that question too! Use Google liberally.\n",
    "---\n",
    "\n",
    "**Task:**\n",
    "- Create a scatterplot of `funded_amount` versus `loan_amount`.\n",
    "- Create a histogram of the `term_in_months` to view the distribution of loan terms.\n",
    "- Using `loans_by_sector` (the grouped DataFrame created in the last section), create a bar plot of the number of loans in each sector. \n",
    "    - Tip: You can use `df.index` to access the index names.\n",
    "    - Try looking [here](https://stackoverflow.com/questions/10998621/rotate-axis-text-in-python-matplotlib/23009503?utm_medium=organic&utm_source=google_rich_qa&utm_campaign=google_rich_qa) for tips on how to rotate tick labels. This was the third Google search result; the first two returned results for more specific scenarios, and the third was exactly what we needed!\n",
    "    - Do we need to include an x-axis label for this chart? Why or why not?\n",
    "- Create a histogram of `loan_amount` to view the distribution of loan amounts.\n",
    "    - Interpret the graph; why did the plotting function set these x-limits?\n",
    "    - How can we work around this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-18T20:27:03.169036Z",
     "start_time": "2018-09-18T20:26:51.225742Z"
    }
   },
   "outputs": [],
   "source": [
    "# Scatterplot, funded_amount vs. loan_amount\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.scatter(...)\n",
    "plt.xlabel('Funded Amount')\n",
    "plt.ylabel('Loan Amount')\n",
    "plt.title('Loan amount vs. Funded amount');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-18T20:27:03.574918Z",
     "start_time": "2018-09-18T20:27:03.174295Z"
    }
   },
   "outputs": [],
   "source": [
    "# Histogram, distribution of loan terms\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.hist(...)\n",
    "# Set an xlabel and a ylabel below!\n",
    "...\n",
    "...\n",
    "plt.title('Distribution of loan term length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-18T20:27:04.210036Z",
     "start_time": "2018-09-18T20:27:03.579576Z"
    }
   },
   "outputs": [],
   "source": [
    "# Bar plot, number of loans in each sector\n",
    "plt.figure(figsize=(10, 7))\n",
    "# Try setting up the barplot below. (Not necessarily limited to one line of code)\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-18T20:27:04.687047Z",
     "start_time": "2018-09-18T20:27:04.212564Z"
    }
   },
   "outputs": [],
   "source": [
    "# Histogram, distribution of loan amount\n",
    "plt.figure(figsize=(10, 7))\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do we get the above result? We can check the numerical distribution of a column using [`df[colname].describe()`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.describe.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-18T20:27:04.793082Z",
     "start_time": "2018-09-18T20:27:04.691874Z"
    }
   },
   "outputs": [],
   "source": [
    "# Taking a look at the data:\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the max loan is 100000, while the 75th percentile is 1000. This is why Matplotlib has decided to extend out our x-limits so widely, to fit in that max data point! In order to avoid this, we should subset the loan amounts in which most of our data lies; 5000 seems like a reasonable estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-18T20:27:05.309648Z",
     "start_time": "2018-09-18T20:27:04.797272Z"
    }
   },
   "outputs": [],
   "source": [
    "# Histogram, distribution of loan amount (without outliers):\n",
    "plt.figure(figsize=(10, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge/Join Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Merge_ and _Join_ are two separate pandas functions but perform similar actions. For the difference between the two: https://stackoverflow.com/questions/22676081/what-is-the-difference-between-join-and-merge-in-pandas\n",
    "\n",
    "The main idea is to combine two dataframes and only keep the rows which have the same certain column values across both dataframes. \n",
    "\n",
    "Walk through the example by running the cells below. \n",
    "\n",
    "\n",
    "We make a dataframe of gdp of 5 countries and a dataframe of the unemployment rate of 3 countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp = pd.DataFrame(columns = ['Countries', 'Price (billions of $)' ])\n",
    "gdp['Countries'] = pd.Series(['United States', 'China', 'India', 'Mexico', 'Austria'])\n",
    "gdp['Price (billions of $)'] = pd.Series([20412.87, 14092.51, 2848.23, 1212.83, 477.67])\n",
    "gdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment = pd.DataFrame(columns = ['Country Name', 'Unemployment Rate' ])\n",
    "unemployment['Country Name'] = pd.Series(['India', 'United States', 'Austria'])\n",
    "unemployment['Unemployment Rate'] = pd.Series([3.7, 5.6, 7.0])\n",
    "unemployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to find the countries for which we have information of both gdp and unemployment rate. \n",
    "\n",
    "So we combine, or _merge_, the gdp and unemployment dataframes based on the names of the countries. Since we are doing gdp _Right Merge/Join_ with unemployment, we keep the rows of the unemployment dataframe where the __Country Name__ column in unemployment = __Countries__ column of gdp.\n",
    "\n",
    "Notice how we had the countries 'India', 'United States', and 'Austria' in our unemployment dataframe and our gdp dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_merge_df = pd.merge(gdp, unemployment, how='right', left_on = 'Countries', right_on ='Country Name')\n",
    "right_merge_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then drop the unnecessary __Country Name__ column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_merge_df.drop('Country Name', 1)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "Python Workshop (MASTER).ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
